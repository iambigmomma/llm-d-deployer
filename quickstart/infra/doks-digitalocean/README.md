# DigitalOcean GPU Kubernetes Cluster - LLM-D éƒ¨ç½²æŒ‡å—

## æ¦‚è¿°

æœ¬æŒ‡å—å°ˆé–€é‡å°åœ¨ DigitalOcean GPU Kubernetes Cluster (DOKS) ä¸Šéƒ¨ç½² LLM-D çš„å¸¸è¦‹å•é¡Œæä¾›è§£æ±ºæ–¹æ¡ˆã€‚ä¸»è¦è§£æ±º NVIDIA Device Plugin é…ç½®å•é¡Œï¼Œç¢ºä¿ GPU è³‡æºèƒ½å¤ æ­£ç¢ºåˆ†é…çµ¦ LLM-D çš„ prefill å’Œ decode podsã€‚

## å•é¡ŒèƒŒæ™¯

### å¸¸è¦‹ç—‡ç‹€

ç•¶åœ¨ DigitalOcean GPU Kubernetes Cluster ä¸Šé‹è¡Œ `llmd-installer.sh` æ™‚ï¼Œæ‚¨å¯èƒ½æœƒé‡åˆ°ä»¥ä¸‹å•é¡Œï¼š

1. **Prefill å’Œ Decode Pods å¡åœ¨ Pending ç‹€æ…‹**

   ```
   NAME                      READY   STATUS    RESTARTS
   prefill-deployment-xxx    0/1     Pending   0
   decode-deployment-xxx     0/2     Pending   0
   ```

2. **Pod äº‹ä»¶é¡¯ç¤ºè³‡æºä¸è¶³**

   ```
   Events:
   Warning  FailedScheduling  pod/prefill-deployment-xxx
   0/2 nodes are available: 2 Insufficient nvidia.com/gpu.
   ```

3. **GPU ç¯€é»æ²’æœ‰å¯ç”¨çš„ GPU è³‡æº**
   ```bash
   kubectl describe node <gpu-node>
   # Allocatable éƒ¨åˆ†ç¼ºå°‘ nvidia.com/gpu
   ```

### æ ¹æœ¬åŸå› 

DigitalOcean GPU Kubernetes Cluster çš„ GPU ç¯€é»ç¼ºå°‘å¿…è¦çš„ Node Feature Discovery (NFD) æ¨™ç±¤ï¼Œå°è‡´ NVIDIA Device Plugin ç„¡æ³•æ­£ç¢ºèª¿åº¦åˆ° GPU ç¯€é»ä¸Šï¼š

- **ç¼ºå°‘æ¨™ç±¤**: `feature.node.kubernetes.io/pci-10de.present=true`
- **å½±éŸ¿**: NVIDIA Device Plugin DaemonSet ç„¡æ³•åœ¨ GPU ç¯€é»ä¸Šé‹è¡Œ
- **çµæœ**: GPU ç¯€é»ç„¡æ³•æš´éœ² `nvidia.com/gpu` è³‡æº

## è§£æ±ºæ–¹æ¡ˆ

### è‡ªå‹•åŒ–è…³æœ¬

æˆ‘å€‘æä¾›äº†ä¸€å€‹å…¨è‡ªå‹•çš„é å®‰è£è…³æœ¬ä¾†è§£æ±ºé€™å€‹å•é¡Œï¼š

```bash
./setup-gpu-cluster.sh
```

### è…³æœ¬åŠŸèƒ½

1. **ç’°å¢ƒé©—è­‰**

   - æª¢æŸ¥å¿…è¦çš„å·¥å…· (kubectl, helm)
   - é©—è­‰ Kubernetes é›†ç¾¤é€£æ¥æ€§
   - ç¢ºèªé€™æ˜¯ DigitalOcean GPU é›†ç¾¤

2. **NVIDIA Device Plugin å®‰è£**

   - ä½¿ç”¨ Helm å®‰è£æœ€æ–°ç‰ˆæœ¬çš„ NVIDIA Device Plugin
   - è‡ªå‹•é…ç½®å¿…è¦çš„ namespace å’Œè¨­ç½®
   - ç­‰å¾… DaemonSet æº–å‚™å°±ç·’

3. **GPU ç¯€é»æ¨™ç±¤ä¿®å¾©**

   - è‡ªå‹•æª¢æ¸¬æ‰€æœ‰ GPU ç¯€é»
   - æ·»åŠ å¿…è¦çš„ NFD æ¨™ç±¤
   - ç¢ºä¿ Device Plugin èƒ½å¤ èª¿åº¦

4. **è³‡æºé©—è­‰**
   - é©—è­‰ GPU è³‡æºæ­£ç¢ºæš´éœ²
   - åŸ·è¡Œå¥åº·æª¢æŸ¥
   - ç¢ºèªç³»çµ±å°±ç·’

## ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬ç”¨æ³•

```bash
# å…‹éš†é …ç›®ä¸¦é€²å…¥ç›®éŒ„
cd quickstart/infra/doks-digitalocean

# è³¦äºˆåŸ·è¡Œæ¬Šé™
chmod +x setup-gpu-cluster.sh

# é‹è¡Œè…³æœ¬
./setup-gpu-cluster.sh
```

### é«˜ç´šé¸é …

```bash
# ä½¿ç”¨è‡ªå®šç¾© kubeconfig
./setup-gpu-cluster.sh --context ~/.kube/my-cluster-config

# å¼·åˆ¶é‡æ–°å®‰è£ NVIDIA Device Plugin
./setup-gpu-cluster.sh --force-reinstall

# é è¦½æ¨¡å¼ (ä¸åŸ·è¡Œå¯¦éš›æ“ä½œ)
./setup-gpu-cluster.sh --dry-run

# æŸ¥çœ‹å¹«åŠ©
./setup-gpu-cluster.sh --help
```

### é æœŸè¼¸å‡º

æˆåŠŸé‹è¡Œå¾Œï¼Œæ‚¨æ‡‰è©²çœ‹åˆ°é¡ä¼¼ä»¥ä¸‹çš„è¼¸å‡ºï¼š

```
ğŸš€ DigitalOcean GPU Kubernetes Cluster é å®‰è£è…³æœ¬
ç‰ˆæœ¬: NVIDIA Device Plugin v0.17.1

â„¹ï¸  ä½¿ç”¨ç•¶å‰çš„ kubectl context
âœ… æˆåŠŸé€£æ¥åˆ° Kubernetes é›†ç¾¤
âœ… æª¢æ¸¬åˆ° 2 å€‹ GPU ç¯€é»
â„¹ï¸  å®‰è£ NVIDIA Device Plugin...
âœ… NVIDIA Device Plugin å®‰è£å®Œæˆ
âœ… NVIDIA Device Plugin DaemonSet å·²å°±ç·’ (2/2)
â„¹ï¸  ä¿®å¾© GPU ç¯€é»æ¨™ç±¤...
âœ… ç¯€é» pool-xxx-1 æ¨™ç±¤ä¿®å¾©å®Œæˆ
âœ… ç¯€é» pool-xxx-2 æ¨™ç±¤ä¿®å¾©å®Œæˆ
âœ… GPU è³‡æºé©—è­‰å®Œæˆ: ç¸½è¨ˆ 2 å€‹ GPUï¼Œå¯ç”¨ 2 å€‹
âœ… å¥åº·æª¢æŸ¥å®Œæˆ
ğŸ‰ DigitalOcean GPU Cluster é å®‰è£å®Œæˆï¼
â„¹ï¸  ç¾åœ¨æ‚¨å¯ä»¥é‹è¡Œ llmd-installer.sh é€²è¡Œ LLM-D éƒ¨ç½²
```

## æ‰‹å‹•è§£æ±ºæ–¹æ¡ˆ

å¦‚æœæ‚¨ä¸æƒ³ä½¿ç”¨è‡ªå‹•åŒ–è…³æœ¬ï¼Œä¹Ÿå¯ä»¥æ‰‹å‹•åŸ·è¡Œä»¥ä¸‹æ­¥é©Ÿï¼š

### 1. å®‰è£ NVIDIA Device Plugin

```bash
# å‰µå»º namespace
kubectl create namespace nvidia-device-plugin

# æ·»åŠ  Helm repository
helm repo add nvdp https://nvidia.github.io/k8s-device-plugin
helm repo update

# å®‰è£ Device Plugin
helm install nvdp nvdp/nvidia-device-plugin \
  --namespace nvidia-device-plugin \
  --version v0.17.1 \
  --wait
```

### 2. è­˜åˆ¥ GPU ç¯€é»

```bash
# æ–¹æ³• 1: ä½¿ç”¨ DigitalOcean æ¨™ç±¤
kubectl get nodes -l doks.digitalocean.com/gpu-brand=nvidia

# æ–¹æ³• 2: ä½¿ç”¨å¯¦ä¾‹é¡å‹
kubectl get nodes -o json | jq -r '.items[] | select(.metadata.labels."node.kubernetes.io/instance-type" | test("gpu-")) | .metadata.name'
```

### 3. æ·»åŠ å¿…è¦æ¨™ç±¤

```bash
# ç‚ºæ¯å€‹ GPU ç¯€é»æ·»åŠ æ¨™ç±¤
kubectl label nodes <gpu-node-1> feature.node.kubernetes.io/pci-10de.present=true
kubectl label nodes <gpu-node-2> feature.node.kubernetes.io/pci-10de.present=true

# å¯é¸ï¼šæ·»åŠ é¡å¤–çš„ GPU æ¨™ç±¤
kubectl label nodes <gpu-node-1> nvidia.com/gpu.present=true
kubectl label nodes <gpu-node-2> nvidia.com/gpu.present=true
```

### 4. é©—è­‰é…ç½®

```bash
# æª¢æŸ¥ Device Plugin pods
kubectl get pods -n nvidia-device-plugin

# é©—è­‰ GPU è³‡æº
kubectl get nodes -o jsonpath='{range .items[*]}{.metadata.name}{"\t"}{.status.allocatable.nvidia\.com/gpu}{"\n"}{end}'

# æª¢æŸ¥ç¯€é»è©³ç´°ä¿¡æ¯
kubectl describe node <gpu-node-name>
```

## éƒ¨ç½² LLM-D

é å®‰è£å®Œæˆå¾Œï¼Œæ‚¨å¯ä»¥æ­£å¸¸é‹è¡Œ LLM-D å®‰è£è…³æœ¬ï¼š

```bash
# è¿”å›åˆ°é …ç›®æ ¹ç›®éŒ„
cd ../../..

# é‹è¡Œ LLM-D å®‰è£è…³æœ¬
./llmd-installer.sh
```

## æ•…éšœæ’é™¤

### Device Plugin Pods ç„¡æ³•å•Ÿå‹•

```bash
# æª¢æŸ¥ DaemonSet ç‹€æ…‹
kubectl get daemonset -n nvidia-device-plugin

# æŸ¥çœ‹ Pod äº‹ä»¶
kubectl describe pods -n nvidia-device-plugin

# æª¢æŸ¥ç¯€é»æ¨™ç±¤
kubectl get nodes --show-labels | grep feature.node.kubernetes.io/pci
```

### GPU è³‡æºä»ç„¶ä¸å¯ç”¨

```bash
# é‡å•Ÿ Device Plugin
kubectl rollout restart daemonset/nvdp-nvidia-device-plugin -n nvidia-device-plugin

# ç­‰å¾… pods é‡æ–°å•Ÿå‹•
kubectl rollout status daemonset/nvdp-nvidia-device-plugin -n nvidia-device-plugin

# é‡æ–°æª¢æŸ¥è³‡æº
kubectl get nodes -o yaml | grep -A 10 -B 10 "nvidia.com/gpu"
```

### LLM-D Pods ä»ç„¶ Pending

```bash
# æª¢æŸ¥ pods äº‹ä»¶
kubectl describe pod -n llm-d -l llm-d.ai/inferenceServing=true

# æª¢æŸ¥è³‡æºè«‹æ±‚
kubectl get pod -n llm-d -o yaml | grep -A 5 -B 5 "nvidia.com/gpu"

# é©—è­‰ Tolerations
kubectl get pod -n llm-d -o yaml | grep -A 10 tolerations
```

## æŠ€è¡“ç´°ç¯€

### NVIDIA Device Plugin å·¥ä½œåŸç†

1. **Device Plugin** ä½œç‚º DaemonSet é‹è¡Œåœ¨æ¯å€‹ GPU ç¯€é»ä¸Š
2. **Node Affinity** è¦æ±‚ç¯€é»å…·æœ‰ç‰¹å®šæ¨™ç±¤æ‰èƒ½èª¿åº¦
3. **Resource Advertising** å‘ Kubernetes API æš´éœ² GPU è³‡æº
4. **Resource Allocation** ç‚ºè«‹æ±‚ GPU çš„ pods åˆ†é…è¨­å‚™

### DigitalOcean GPU ç¯€é»ç‰¹æ€§

- **å¯¦ä¾‹é¡å‹**: é€šå¸¸åŒ…å« "gpu-" å‰ç¶´
- **GPU å“ç‰Œ**: NVIDIA Tesla ç³»åˆ—
- **é©…å‹•ç¨‹åº**: é å®‰è£ NVIDIA é©…å‹•
- **å®¹å™¨é‹è¡Œæ™‚**: æ”¯æŒ NVIDIA Container Runtime

### æ¨™ç±¤èªªæ˜

| æ¨™ç±¤                                               | ç”¨é€”                  | ä¾†æº                |
| -------------------------------------------------- | --------------------- | ------------------- |
| `feature.node.kubernetes.io/pci-10de.present=true` | NVIDIA PCI è¨­å‚™æª¢æ¸¬   | NFD æˆ–æ‰‹å‹•æ·»åŠ       |
| `nvidia.com/gpu.present=true`                      | GPU å­˜åœ¨æ¨™è­˜          | æ‰‹å‹•æ·»åŠ             |
| `doks.digitalocean.com/gpu-brand=nvidia`           | DigitalOcean GPU å“ç‰Œ | DOKS è‡ªå‹•æ·»åŠ        |
| `node.kubernetes.io/instance-type`                 | ç¯€é»å¯¦ä¾‹é¡å‹          | Kubernetes è‡ªå‹•æ·»åŠ  |

## æ”¯æŒçš„ DigitalOcean GPU å¯¦ä¾‹

| å¯¦ä¾‹é¡å‹                     | GPU å‹è™Ÿ     | GPU æ•¸é‡ | è¨˜æ†¶é«” |
| ---------------------------- | ------------ | -------- | ------ |
| `gpu-nvidia-rtx-4000-ada-x1` | RTX 4000 Ada | 1        | 20GB   |
| `gpu-nvidia-rtx-4000-ada-x2` | RTX 4000 Ada | 2        | 40GB   |
| `gpu-nvidia-rtx-4000-ada-x4` | RTX 4000 Ada | 4        | 80GB   |
| `gpu-nvidia-h100-x1`         | H100         | 1        | 80GB   |
| `gpu-nvidia-h100-x2`         | H100         | 2        | 160GB  |
| `gpu-nvidia-h100-x4`         | H100         | 4        | 320GB  |
| `gpu-nvidia-h100-x8`         | H100         | 8        | 640GB  |

## æœ€ä½³å¯¦è¸

### 1. è³‡æºè¦åŠƒ

- **æ¯å€‹ GPU** åªèƒ½è¢«å–®å€‹ pod ä½¿ç”¨
- **Prefill Pod** é€šå¸¸éœ€è¦ 1 å€‹ GPU
- **Decode Pod** å¯èƒ½éœ€è¦ 1-2 å€‹ GPU (å–æ±ºæ–¼é…ç½®)
- **é ç•™è³‡æº** ç‚ºç³»çµ±å’Œå…¶ä»–æœå‹™ç•™å‡ºç©ºé–“

### 2. ç›£æ§å’Œç¶­è­·

```bash
# å®šæœŸæª¢æŸ¥ GPU ä½¿ç”¨ç‡
kubectl top nodes

# ç›£æ§ Device Plugin ç‹€æ…‹
kubectl get pods -n nvidia-device-plugin -w

# æª¢æŸ¥è³‡æºåˆ†é…
kubectl describe nodes | grep -A 5 -B 5 "nvidia.com/gpu"
```

### 3. å‡ç´šå’Œæ›´æ–°

```bash
# æ›´æ–° Device Plugin
helm upgrade nvdp nvdp/nvidia-device-plugin -n nvidia-device-plugin

# æª¢æŸ¥å¯ç”¨ç‰ˆæœ¬
helm search repo nvdp
```

## ç›¸é—œè³‡æº

- [NVIDIA Device Plugin å®˜æ–¹æ–‡æª”](https://github.com/NVIDIA/k8s-device-plugin)
- [DigitalOcean GPU Kubernetes æœå‹™](https://docs.digitalocean.com/products/kubernetes/how-to/add-gpu-nodes/)
- [Kubernetes GPU èª¿åº¦](https://kubernetes.io/docs/tasks/manage-gpus/scheduling-gpus/)
- [Node Feature Discovery](https://kubernetes-sigs.github.io/node-feature-discovery/)

## å¸¸è¦‹å•é¡Œ (FAQ)

### Q: ç‚ºä»€éº¼éœ€è¦æ‰‹å‹•æ·»åŠ æ¨™ç±¤ï¼Ÿ

A: DigitalOcean çš„ GPU ç¯€é»æ²’æœ‰é è£ Node Feature Discovery (NFD)ï¼Œå› æ­¤ç¼ºå°‘ NVIDIA Device Plugin æ‰€éœ€çš„ PCI è¨­å‚™æ¨™ç±¤ã€‚

### Q: é€™å€‹è§£æ±ºæ–¹æ¡ˆæ˜¯å¦é©ç”¨æ–¼å…¶ä»–é›²æœå‹™æä¾›å•†ï¼Ÿ

A: æ­¤è§£æ±ºæ–¹æ¡ˆå°ˆé–€é‡å° DigitalOcean è¨­è¨ˆï¼Œå…¶ä»–é›²æœå‹™æä¾›å•†å¯èƒ½æœ‰ä¸åŒçš„é…ç½®éœ€æ±‚ã€‚

### Q: å¦‚ä½•ç¢ºèª GPU é©…å‹•ç¨‹åºæ­£ç¢ºå®‰è£ï¼Ÿ

A: å¯ä»¥åœ¨ GPU ç¯€é»ä¸Šé‹è¡Œ `nvidia-smi` å‘½ä»¤ï¼Œæˆ–æª¢æŸ¥ Device Plugin pods çš„æ—¥èªŒã€‚

### Q: Device Plugin é‡å•Ÿæœƒå½±éŸ¿æ­£åœ¨é‹è¡Œçš„ pods å—ï¼Ÿ

A: ä¸æœƒã€‚Device Plugin é‡å•Ÿä¸æœƒå½±éŸ¿å·²ç¶“åˆ†é…äº† GPU è³‡æºçš„é‹è¡Œä¸­ podsã€‚

### Q: å¯ä»¥åœ¨åŒä¸€å€‹é›†ç¾¤ä¸Šé‹è¡Œå¤šå€‹ LLM-D å¯¦ä¾‹å—ï¼Ÿ

A: å¯ä»¥ï¼Œä½†éœ€è¦ç¢ºä¿æœ‰è¶³å¤ çš„ GPU è³‡æºï¼Œä¸¦ä¸”æ¯å€‹å¯¦ä¾‹ä½¿ç”¨ä¸åŒçš„ namespaceã€‚

## ğŸš€ Quick Start with Pre-configured GPU Settings

### GPU Configuration Files

We provide optimized configuration files for different GPU models:

| GPU Model           | VRAM | Configuration File                     | Max Sequence Length |
| ------------------- | ---- | -------------------------------------- | ------------------- |
| NVIDIA RTX 4000 Ada | 20GB | `gpu-configs/rtx-4000-ada-values.yaml` | 8,192               |
| NVIDIA RTX 6000 Ada | 48GB | `gpu-configs/rtx-6000-ada-values.yaml` | 16,384              |
| NVIDIA L40S         | 48GB | `gpu-configs/l40s-values.yaml`         | 20,480              |

### One-Command Deployment

Use the unified deployment script with monitoring:

```bash
# Deploy with RTX 4000 Ada
./deploy-with-monitoring.sh -g rtx-4000-ada -t your_hf_token_here

# Deploy with RTX 6000 Ada
./deploy-with-monitoring.sh -g rtx-6000-ada -t your_hf_token_here

# Deploy with L40S
./deploy-with-monitoring.sh -g l40s -t your_hf_token_here

# Deploy without monitoring
./deploy-with-monitoring.sh -g rtx-4000-ada -t your_hf_token_here -m
```

### Manual Deployment

If you prefer manual deployment:

```bash
# Go to quickstart directory
cd ../../

# Set your HuggingFace token
export HF_TOKEN=your_token_here

# Deploy with specific GPU configuration
./llmd-installer.sh -f infra/doks-digitalocean/gpu-configs/rtx-4000-ada-values.yaml

# Set up monitoring (optional)
cd infra/doks-digitalocean/monitoring
./setup-monitoring.sh
```

## ğŸ“Š Monitoring and Dashboards

### Included Monitoring Stack

- **Prometheus**: Metrics collection and storage
- **Grafana**: Visualization dashboards
- **AlertManager**: Alert handling
- **Node Exporter**: Node-level metrics
- **Custom LLM-D Dashboard**: Inference-specific metrics

### Monitoring Setup

The monitoring system is automatically installed with the deployment script, or you can install it separately:

```bash
cd infra/doks-digitalocean/monitoring
chmod +x setup-monitoring.sh
./setup-monitoring.sh
```

### Access Monitoring

```bash
# Access Grafana
kubectl port-forward -n llm-d-monitoring svc/prometheus-grafana 3000:80
# Open http://localhost:3000
# Username: admin, Password: admin

# Access Prometheus
kubectl port-forward -n llm-d-monitoring svc/prometheus-kube-prometheus-prometheus 9090:9090
# Open http://localhost:9090
```

### Monitoring Metrics

The LLM-D dashboard includes:

- **Active Pods**: Number of running model service pods
- **Request Rate**: Inference requests per second
- **Response Time**: Average latency and percentiles
- **GPU Memory Usage**: Memory utilization across pods
- **Token Throughput**: Tokens processed per second
- **Queue Status**: Request queue depth
- **Error Rates**: Failed request monitoring

## ğŸ”§ GPU Configuration Details

### RTX 4000 Ada (20GB VRAM)

```yaml
# Memory-optimized for 20GB VRAM
sampleApplication:
  decode:
    extraArgs:
      - "--max-model-len"
      - "8192" # Reduced for memory efficiency
      - "--gpu-memory-utilization"
      - "0.85" # Use 85% of GPU memory
      - "--enforce-eager" # Disable CUDA graph
  # ... resource limits: 1 GPU, 32Gi memory, 8 CPU cores
```

### RTX 6000 Ada (48GB VRAM)

```yaml
# Optimized for 48GB VRAM
sampleApplication:
  decode:
    extraArgs:
      - "--max-model-len"
      - "16384" # Higher sequence length
      - "--gpu-memory-utilization"
      - "0.85"
      - "--kv-cache-dtype"
      - "fp8" # Memory-efficient cache
  # ... resource limits: 1 GPU, 64Gi memory, 16 CPU cores
```

### L40S (48GB VRAM)

```yaml
# High-performance configuration
sampleApplication:
  decode:
    extraArgs:
      - "--max-model-len"
      - "20480" # Maximum sequence length
      - "--gpu-memory-utilization"
      - "0.85"
      - "--kv-cache-dtype"
      - "fp8"
  # ... resource limits: 1 GPU, 96Gi memory, 24 CPU cores
```

## ğŸ“‹ Management Commands

### Deployment Script Options

```bash
./deploy-with-monitoring.sh [OPTIONS]

Options:
    -g, --gpu TYPE          GPU type (rtx-4000-ada, rtx-6000-ada, l40s)
    -t, --token TOKEN       HuggingFace token (required)
    -m, --no-monitoring     Skip monitoring installation
    -u, --uninstall         Uninstall LLM-D and monitoring
    -h, --help              Show help message
```

### Uninstall Everything

```bash
# Uninstall LLM-D and monitoring
./deploy-with-monitoring.sh -u

# Or manually
cd ../../
./llmd-installer.sh -u
helm uninstall prometheus -n llm-d-monitoring
kubectl delete namespace llm-d-monitoring
```

### Testing the Deployment

```bash
# Run comprehensive tests
cd ../../
./test-request.sh

# Manual testing
# Get gateway IP
kubectl get svc -n istio-system istio-ingressgateway

# Test models endpoint
curl -H "Host: inference.example.com" http://<GATEWAY_IP>/v1/models

# Test completion
curl -H "Host: inference.example.com" http://<GATEWAY_IP>/v1/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "meta-llama/Llama-3.2-3B-Instruct",
    "prompt": "Hello, how are you?",
    "max_tokens": 100
  }'
```

## ğŸ” Troubleshooting

### Common Issues

1. **GPU Memory Issues**

   - Check GPU memory usage: `kubectl logs -n llm-d <pod-name> -c vllm`
   - Reduce `max-model-len` if out of memory
   - Lower `gpu-memory-utilization` value

2. **Pod Not Starting**

   - Check events: `kubectl describe pod -n llm-d <pod-name>`
   - Verify HuggingFace token: `kubectl get secret -n llm-d`
   - Check resource availability: `kubectl describe nodes`

3. **Monitoring Issues**
   - Check monitoring pods: `kubectl get pods -n llm-d-monitoring`
   - Verify ServiceMonitor: `kubectl get servicemonitor -n llm-d-monitoring`
   - Check Prometheus targets: Access Prometheus UI â†’ Status â†’ Targets

### Logs and Debugging

```bash
# LLM-D application logs
kubectl logs -n llm-d deployment/meta-llama-llama-3-2-3b-instruct-decode -c vllm

# Gateway logs
kubectl logs -n istio-system deployment/istio-ingressgateway

# Monitoring logs
kubectl logs -n llm-d-monitoring deployment/prometheus-grafana
kubectl logs -n llm-d-monitoring statefulset/prometheus-prometheus-kube-prometheus-prometheus
```

### Performance Tuning

1. **Memory Optimization**

   - Adjust `gpu-memory-utilization` (0.7-0.95)
   - Use `fp8` for KV cache on supported models
   - Enable `enforce-eager` for memory savings

2. **Throughput Optimization**

   - Increase `max-model-len` if memory allows
   - Disable `enforce-eager` for better performance
   - Adjust batch sizes based on workload

3. **Resource Allocation**
   - Monitor CPU and memory usage in Grafana
   - Adjust resource requests/limits based on actual usage
   - Consider multi-GPU setup for larger models

## ğŸ“š Additional Resources

- [Original DOKS Setup Guide](setup-gpu-cluster.sh)
- [LLM-D Documentation](../../README.md)
- [Kubernetes GPU Guide](https://kubernetes.io/docs/tasks/manage-gpus/scheduling-gpus/)
- [Prometheus Operator](https://prometheus-operator.dev/)
- [Grafana Documentation](https://grafana.com/docs/)

## ğŸ¤ Contributing

When adding new GPU configurations:

1. Create a new values file in `gpu-configs/`
2. Update the deployment script with the new GPU type
3. Add monitoring configurations if needed
4. Update this README with the new GPU specifications
5. Test thoroughly with the new configuration
